{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组C题代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题一：数据清洗及描述统计\r\n",
    "1. 绘图与简单描述统计\r\n",
    "2. 相关性、方差齐性等检验\r\n",
    "3. 正态化、Box-Cox"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 绘图与简单描述统计\r\n",
    "# 原文件：DataProcess.py\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns \r\n",
    "\r\n",
    "# 支持中文\r\n",
    "plt.rcParams['font.sans-serif'] = ['SimSun']  # 用来正常显示中文标签\r\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\r\n",
    "sns.set_palette(\"husl\")\r\n",
    "plt.style.use('ggplot')\r\n",
    "\r\n",
    "allDf = pd.read_excel('Data\\\\OriginData.xlsx')\r\n",
    "allDf = allDf[pd.notna(allDf['品牌类型'])]  # 把原数据中1969行之后本不应该存在的数据删掉\r\n",
    "\r\n",
    "# 数据预处理1：剔除a1到a8中超过100的数据\r\n",
    "for i in list(allDf)[2: 10]:\r\n",
    "    allDf = allDf[allDf[i] <= 100]\r\n",
    "allDf = allDf[allDf['B17'] <= 100]\r\n",
    "\r\n",
    "# 绘制箱线图\r\n",
    "def boxPlot(name, fname):\r\n",
    "    # plt.boxplot(column=name[2: 10], showmeans=True, labels=list(name)[2:10],showcaps=True, showbox=True)\r\n",
    "    name.boxplot(column=list(name)[2: 10], showmeans=True)\r\n",
    "    plt.title('各项满意度得分')\r\n",
    "    # plt.show()\r\n",
    "    plt.savefig('Fig\\\\boxPlot\\\\' + fname + '.png', bbox_inches='tight')\r\n",
    "    plt.close()\r\n",
    "\r\n",
    "# 数据预处理2：婚姻关系修正\r\n",
    "\r\n",
    "allDf = allDf[(allDf['B6'] != 1) | (allDf['B5'] == 1)] # 剔除未婚单独居住但是家庭成员超过1, 3\r\n",
    "allDf = allDf[(allDf['B6'] != 2) | (allDf['B5'] <= 3)]  # 剔除与父母同居但是家庭成员超过3的 1\r\n",
    "allDf = allDf[(allDf['B6'] != 3) | (allDf['B5'] == 2)]  # 剔除二人世界但是家庭成员不为2（事先已经检查过没有1） 0\r\n",
    "allDf = allDf[(allDf['B6'] != 3) | (pd.isna(allDf['B7']))]  # 剔除二人世界但是有小孩的 4\r\n",
    "allDf = allDf[(allDf['B6'] != 4) | (pd.isna(allDf['B7']))]  # 剔除二人世界但是有小孩的 0\r\n",
    "allDf = allDf[(allDf['B6'] != 5) | (pd.notna(allDf['B7']))] # 剔除已婚有小孩但是B7没数据的 0\r\n",
    "allDf = allDf[(allDf['B6'] != 5) | (allDf['B5'] - allDf['B7'] <= 2)] # 剔除已婚有小孩不与父母同居但是人数不对应的 2\r\n",
    "\r\n",
    "# 数据预处理3：收入关系修正\r\n",
    "\r\n",
    "allDf = allDf[allDf['B13'] >= allDf['B14']]\r\n",
    "allDf = allDf[allDf['B13'] >= allDf['B15']]\r\n",
    "allDf = allDf[allDf['B16'] + allDf['B17'] < 100]\r\n",
    "\r\n",
    "tempDf1 = allDf[pd.isna(allDf['B7'])]\r\n",
    "tempDf2 = allDf[pd.notna(allDf['B7'])]\r\n",
    "a = len(tempDf1['B7'])\r\n",
    "tempDf1['B7'] = [0 for i in range(a)]\r\n",
    "allDf = tempDf1.append(tempDf2)\r\n",
    "\r\n",
    "# 数据预处理4：剔除3IQR\r\n",
    "def cleanTooSmall(name):\r\n",
    "    mean = [name[i].median() for i in list(name)[2:10]]\r\n",
    "    IQR = [name[i].quantile(.75) - name[i].quantile(.25) for i in list(name)[2:10]]\r\n",
    "    # print(mu, sigma)\r\n",
    "    tmp = 0\r\n",
    "    for i in list(name)[2: 10]:\r\n",
    "        name = name[(name[i] >= mean[tmp] - 3 * IQR[tmp]) | (name[i] <= mean[tmp] + 3 * IQR[tmp])]\r\n",
    "        tmp += 1\r\n",
    "    return name\r\n",
    "\r\n",
    "# 数据预处理5：出生年月 -> 年龄\r\n",
    "ltmp = [2021 - i for i in list(allDf['B8'])]\r\n",
    "allDf['B8'] = ltmp\r\n",
    "\r\n",
    "\r\n",
    "# 数据预处理6：拆分三款汽车\r\n",
    "dfType1 = allDf[allDf['品牌类型'] == 1]\r\n",
    "dfType2 = allDf[allDf['品牌类型'] == 2]\r\n",
    "dfType3 = allDf[allDf['品牌类型'] == 3]\r\n",
    "\r\n",
    "dfType1 = cleanTooSmall(dfType1)\r\n",
    "dfType2 = cleanTooSmall(dfType2)\r\n",
    "dfType3 = cleanTooSmall(dfType3)\r\n",
    "\r\n",
    "\r\n",
    "allDf = dfType1.append(dfType2.append(dfType3))\r\n",
    "\r\n",
    "boxPlot(allDf, 'main')\r\n",
    "boxPlot(dfType1, 'type1')\r\n",
    "boxPlot(dfType2, 'type2')\r\n",
    "boxPlot(dfType3, 'type3')\r\n",
    "\r\n",
    "dfType1.to_csv('Data\\\\Type1.csv', index = False)\r\n",
    "dfType2.to_csv('Data\\\\Type2.csv', index = False)\r\n",
    "dfType3.to_csv('Data\\\\Type3.csv', index = False)\r\n",
    "allDf.to_csv('Data\\\\process.csv', index = False)\r\n",
    "\r\n",
    "\r\n",
    "# 数据可视化\r\n",
    "# ax部分绘制直方图\r\n",
    "\r\n",
    "tmp = 0\r\n",
    "for i in list(allDf)[2: 10]:\r\n",
    "    titles = ['电池技术性能', '舒适性', '经济性',\r\n",
    "        '安全性', '动力性', '驾驶操控性',\r\n",
    "        '外观内饰', '配置与质量品质']\r\n",
    "    distance = 5   # 组距\r\n",
    "    group_num = 10\r\n",
    "    sns.histplot(allDf[i], color='r', kde=True,bins=10, alpha=0.3, common_bins=True,stat='probability')\r\n",
    "    \r\n",
    "    # sns.histplot(dfType2[i], color='g', kde=True,bins=10, alpha=0.3, common_bins=True,stat='probability')\r\n",
    "    # sns.histplot(allDf[i], color='b', kde=True,bins=10, alpha=0.3, common_bins=True,stat='probability')\r\n",
    "    \r\n",
    "    mu = allDf[i].mean()\r\n",
    "    sigma = allDf[i].std()\r\n",
    "    m = allDf[i].median()\r\n",
    "    \r\n",
    "    plt.title(titles[tmp])\r\n",
    "    # plt.title(titles[tmp])\r\n",
    "    plt.savefig('Fig\\\\allHist\\\\' + i + '.png', bbox_inches='tight')\r\n",
    "    plt.close()\r\n",
    "    tmp += 1\r\n",
    "\r\n",
    "# bx部分\r\n",
    "def cBar(name, comment, *labelName):\r\n",
    "    x = list(set(allDf[name]))\r\n",
    "    xName = labelName\r\n",
    "    y = [len(allDf[allDf[name] == l]) for l in x]\r\n",
    "    tmpDf = pd.DataFrame({comment: x, '人数': y})\r\n",
    "    ax = sns.barplot(x=comment, y='人数', data=tmpDf, orient='h')\r\n",
    "    ax.set_yticklabels(labelName[0])\r\n",
    "    # plt.xlabel(comment)\r\n",
    "    # plt.xlabel('人数')\r\n",
    "    plt.title(comment)\r\n",
    "    plt.xlabel('')\r\n",
    "    plt.ylabel('')\r\n",
    "    plt.savefig('Fig\\\\characters\\\\' + name + '.png', bbox_inches='tight')\r\n",
    "    plt.close()\r\n",
    "\r\n",
    "def cPie(name, comment, labelName):\r\n",
    "    label = list(set(allDf[name]))\r\n",
    "    x = [len(allDf[allDf[name] == l]) for l in label]\r\n",
    "    plt.pie(x, autopct='%.1f%%')\r\n",
    "    plt.title(comment)\r\n",
    "    plt.legend(labelName)\r\n",
    "    plt.savefig('Fig\\\\characters\\\\' + name + '.png', bbox_inches='tight')\r\n",
    "    plt.close()\r\n",
    "\r\n",
    "def cHist(name, comment):\r\n",
    "    sns.displot(allDf[name], bins=10, kde=True)\r\n",
    "    plt.xlabel(comment)\r\n",
    "    # plt.ylabel('人数')\r\n",
    "    mu = allDf[name].mean()\r\n",
    "    sigma = allDf[name].std()\r\n",
    "    m = allDf[name].median()\r\n",
    "    plt.title(comment+'\\n平均数：{}，标准差：{}，中位数：{}'.format(round(mu, 3), round(sigma, 3), round(m, 3)))\r\n",
    "    # plt.text(2, 8, '$\\mu=${},$\\sigma=${}'.format(round(mu, 3), round(sigma, 3)))\r\n",
    "    plt.savefig('Fig\\\\characters\\\\' + name + '.png', bbox_inches='tight')\r\n",
    "    plt.close()\r\n",
    "\r\n",
    "cPie('B1', '户口情况', ('户口在老家', '户口在本城市', '表示其他'))\r\n",
    "cHist('B2', '居住年数')\r\n",
    "cBar('B3', '居住区域', ('市中心', '非市中心的城区', '城乡结合部', '县城', '乡镇中心地带', '农村'))\r\n",
    "cHist('B4', '驾龄')\r\n",
    "cPie('B5', '家庭人口数', (1,2,3,4,5,6))\r\n",
    "cBar('B6', '婚姻情况', ('未婚，单独居住', '未婚，与父母同住', '已婚/同居无子女（两人世界）', '已婚/同居无子女（与父母同住）', '已婚，有小孩，不与父母同住', '已婚，有小孩，与父母同住', '离异/丧偶', '其他'))\r\n",
    "cPie('B7', '孩子的数量', (0,1,2,3))\r\n",
    "cHist('B8', '年龄')\r\n",
    "cBar('B9', '学历', ('初中', '高中/中专/技校', '大专', '本科', '双学位/研究生及以上'))\r\n",
    "cHist('B10', '工龄')\r\n",
    "cBar('B11', '所在单位性质', ('机关单位/政府部门/基层组织', '科研/教育/文化/卫生/医疗等事业单位', '国有企业', '私营/民营企业（雇员人数在8人以上）', '外资企业', '合资企业', '个体户/小型公司（雇员人数在8人以下）', '自由职业者', '不工作'))\r\n",
    "cBar('B12', '职位', ('高层管理者/企业主/老板', '中层管理者', '资深技术人员/高级技术人员', '中级技术人员', '初级技术人员', '资深职员/办事员', '中级职员/办事员', '初级职员/办事员', '个体户/小型公司业主', '自由职业者', '其他'))\r\n",
    "cHist('B13', '家庭年收入（单位：万元）')\r\n",
    "cHist('B14', '个人年收入（单位：万元）')\r\n",
    "cHist('B15', '家庭可支配年收入（单位：万元）')\r\n",
    "cHist('B16', '房贷支出占比（单位：%）')\r\n",
    "cHist('B17', '车贷支出占比（单位：%）')\r\n",
    "\r\n",
    "# ==========描述统计部分=============\r\n",
    "# 均值与方差\r\n",
    "def outputDiscription(name, fname):\r\n",
    "    mu = [name[i].mean() for i in list(name)[2: 10]]\r\n",
    "    sigma = [name[i].std() for i in list(name)[2: 10]]\r\n",
    "    median = [np.median(name[i]) for i in list(name)[2: 10]]\r\n",
    "    \r\n",
    "    with open('Data\\\\Discription\\\\' + fname + '.csv', 'w', encoding='utf-8') as f:\r\n",
    "        f.write(',')\r\n",
    "        f.write(','.join(list(name)[2:10]))\r\n",
    "        f.write('\\n')\r\n",
    "        f.write('均值,')\r\n",
    "        f.write(','.join([str(s) for s in mu]))\r\n",
    "        f.write('\\n')\r\n",
    "        f.write('标准差,')\r\n",
    "        f.write(','.join([str(s) for s in sigma]))\r\n",
    "        f.write('\\n')\r\n",
    "        f.write('中位数,')\r\n",
    "        f.write(','.join([str(s) for s in median]))\r\n",
    "    return mu, sigma, median\r\n",
    "\r\n",
    "type1Dis = outputDiscription(dfType1, 'type1')\r\n",
    "type2Dis = outputDiscription(dfType2, 'type2')\r\n",
    "type3Dis = outputDiscription(dfType3, 'type3')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 相关性、方差齐性等检验\r\n",
    "# 原文件：DataTest.py\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import math as math\r\n",
    "import numpy as np\r\n",
    "from numpy import *\r\n",
    "from scipy.stats import bartlett\r\n",
    "\r\n",
    "# 注：这里读取的csv文件随任务要求需要修改\r\n",
    "def main():\r\n",
    "    df=pd.read_csv(\"Data\\\\BigData.csv\")\r\n",
    "    df = df[list(['a{}'.format(i) for i in range(1,9)])]\r\n",
    "    df2=df.copy()\r\n",
    "\r\n",
    "    # 皮尔森相关系数\r\n",
    "    df2_corr=df2.corr()\r\n",
    "    print(\"\\n相关系数:\\n\",df2_corr)\r\n",
    "\r\n",
    "    # KMO测度\r\n",
    "    def kmo(dataset_corr):\r\n",
    "        corr_inv = np.linalg.inv(dataset_corr)\r\n",
    "        nrow_inv_corr, ncol_inv_corr = dataset_corr.shape\r\n",
    "        A = np.ones((nrow_inv_corr, ncol_inv_corr))\r\n",
    "        for i in range(0, nrow_inv_corr, 1):\r\n",
    "            for j in range(i, ncol_inv_corr, 1):\r\n",
    "                A[i, j] = -(corr_inv[i, j]) / (math.sqrt(corr_inv[i, i] * corr_inv[j, j]))\r\n",
    "                A[j, i] = A[i, j]\r\n",
    "        dataset_corr = np.asarray(dataset_corr)\r\n",
    "        kmo_num = np.sum(np.square(dataset_corr)) - np.sum(np.square(np.diagonal(A)))\r\n",
    "        kmo_denom = kmo_num + np.sum(np.square(A)) - np.sum(np.square(np.diagonal(A)))\r\n",
    "        kmo_value = kmo_num / kmo_denom\r\n",
    "        return kmo_value\r\n",
    "\r\n",
    "    print(\"\\nKMO测度:\", kmo(df2_corr))\r\n",
    "\r\n",
    "    # 巴特利特球形检验\r\n",
    "    df2_corr1 = df2_corr.values\r\n",
    "    print(\"\\n巴特利特球形检验:\", bartlett(df2['a1'], df2['a2'], df2['a3'], df2['a4'], df2['a5'], df2['a6'], df2['a7'], df2['a8']))\r\n",
    "\r\n",
    "    # 偏度系数与峰度系数\r\n",
    "    for i in list(df2):\r\n",
    "        print(i, df2[i].skew(), df[i].kurt())\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    main()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 正态化等\r\n",
    "# 原文件：Normalize.py\r\n",
    "from scipy.stats import boxcox\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# 支持中文\r\n",
    "plt.rcParams['font.sans-serif'] = ['SimSun']  # 用来正常显示中文标签\r\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\r\n",
    "sns.set_palette(\"husl\")\r\n",
    "plt.style.use('ggplot')\r\n",
    "\r\n",
    "# 这里读取的文件随任务需求而修改\r\n",
    "df = pd.read_csv('Data\\\\testData.csv')\r\n",
    "\r\n",
    "changeList = list(['a{}'.format(i) for i in range(1, 9)])\r\n",
    "for i in changeList:\r\n",
    "    df[i], lamb = boxcox(df[i], lmbda=None, alpha=None)\r\n",
    "    mu, sigma = df[i].mean(), df[i].std()\r\n",
    "\r\n",
    "    df[i] = list([(j-mu)/sigma for j in df[i]]) # z-score\r\n",
    "    # print(type(df[i].values))\r\n",
    "    tmp = df[i].values * np.power(np.absolute(df[i].values), -0.1)\r\n",
    "    # print(type(tmp), tmp)\r\n",
    "    df[i] = tmp\r\n",
    "\r\n",
    "df.to_csv('Data\\\\testDataNorm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题二：各种因素对不同品牌电动汽车购买的影响\r\n",
    "1. 主成分分析（PCA）\r\n",
    "2. 过采样（ADASYN）\r\n",
    "3. 卡方检验\r\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 主成分分析\r\n",
    "# 原文件：PCA.py\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sklearn.decomposition as dp\r\n",
    "from sklearn.preprocessing import scale\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "allDf = pd.read_csv('Data\\\\BigData_0.csv')\r\n",
    "\r\n",
    "plt.rcParams['font.sans-serif'] = ['SimSun']  # 用来正常显示中文标签\r\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\r\n",
    "sns.set_palette(\"husl\")\r\n",
    "plt.style.use('ggplot')\r\n",
    "\r\n",
    "# x = allDf[['B{}'.format(i) for i in range(1,18)]]\r\n",
    "x = allDf[['a{}'.format(i) for i in range(1, 9)]]\r\n",
    "x = scale(x.values)\r\n",
    "y = allDf['购买意愿']\r\n",
    "\r\n",
    "pca = dp.PCA(n_components=8)\r\n",
    "reduce_x = pca.fit_transform(x)\r\n",
    "\r\n",
    "# print(reduce_x)\r\n",
    "\r\n",
    "# print(pca.explained_variance_)          # 输出特征根\r\n",
    "print(pca.explained_variance_ratio_.tolist())    # 输出解释方差比\r\n",
    "print(pca.components_.tolist())                  # 输出主成分\r\n",
    "\r\n",
    "drawD = pd.DataFrame({'序号':list(range(1,9)), '解释方差占比':pca.explained_variance_ratio_.tolist()})\r\n",
    "\r\n",
    "sns.lineplot(x='序号',y='解释方差占比',data=drawD, markers=\"o\")\r\n",
    "\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 过采样\r\n",
    "# 原文件：ADASYN.py\r\n",
    "# 主要源代码来自网络：https://github.com/stavskal/ADASYN\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import unicode_literals\r\n",
    "\r\n",
    "import warnings\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.neighbors import NearestNeighbors\r\n",
    "from sklearn.utils import check_array, check_random_state\r\n",
    "from collections import Counter\r\n",
    "from random import randint\r\n",
    "import math\r\n",
    "\r\n",
    "class ADASYN(object):\r\n",
    "    \"\"\"\r\n",
    "    Oversampling parent class with the main methods required by scikit-learn:\r\n",
    "    fit, transform and fit_transform\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self,\r\n",
    "                 ratio=0.5,\r\n",
    "                 imb_threshold=0.5,\r\n",
    "                 k=5,\r\n",
    "                 random_state=None,\r\n",
    "                 verbose=True):\r\n",
    "        \"\"\"\r\n",
    "        :ratio:\r\n",
    "            Growth percentage with respect to initial minority\r\n",
    "            class size. For example if ratio=0.65 then after\r\n",
    "            resampling minority class(es) will have 1.65 times\r\n",
    "            its initial size\r\n",
    "        :imb_threshold:\r\n",
    "            The imbalance ratio threshold to allow/deny oversampling.\r\n",
    "            For example if imb_threshold=0.5 then minority class needs\r\n",
    "            to be at most half the size of the majority in order for\r\n",
    "            resampling to apply\r\n",
    "        :k:\r\n",
    "            Number of K-nearest-neighbors\r\n",
    "        :random_state:\r\n",
    "            seed for random number generation\r\n",
    "        :verbose:\r\n",
    "            Determines if messages will be printed to terminal or not\r\n",
    "        Extra Instance variables:\r\n",
    "        :self.X:\r\n",
    "            Feature matrix to be oversampled\r\n",
    "        :self.y:\r\n",
    "            Class labels for data\r\n",
    "        :self.clstats:\r\n",
    "            Class populations to determine minority/majority\r\n",
    "        :self.unique_classes_:\r\n",
    "            Number of unique classes\r\n",
    "        :self.maj_class_:\r\n",
    "            Label of majority class\r\n",
    "        :self.random_state_:\r\n",
    "            Seed\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        self.ratio = ratio\r\n",
    "        self.imb_threshold = imb_threshold\r\n",
    "        self.k = k\r\n",
    "        self.random_state = random_state\r\n",
    "        self.verbose = verbose\r\n",
    "        self.clstats = {}\r\n",
    "        self.num_new = 0\r\n",
    "        self.index_new = []\r\n",
    "\r\n",
    "\r\n",
    "    def fit(self, X, y):\r\n",
    "        \"\"\"\r\n",
    "        Class method to define class populations and store them as instance\r\n",
    "        variables. Also stores majority class label\r\n",
    "        \"\"\"\r\n",
    "        self.X = check_array(X)\r\n",
    "        self.y = np.array(y).astype(np.int64)\r\n",
    "        self.random_state_ = check_random_state(self.random_state)\r\n",
    "        self.unique_classes_ = set(self.y)\r\n",
    "\r\n",
    "        # Initialize all class populations with zero\r\n",
    "        for element in self.unique_classes_:\r\n",
    "            self.clstats[element] = 0\r\n",
    "\r\n",
    "        # Count occurences of each class\r\n",
    "        for element in self.y:\r\n",
    "            self.clstats[element] += 1\r\n",
    "\r\n",
    "        # Find majority class\r\n",
    "        v = list(self.clstats.values())\r\n",
    "        k = list(self.clstats.keys())\r\n",
    "        self.maj_class_ = k[v.index(max(v))]\r\n",
    "\r\n",
    "        if self.verbose:\r\n",
    "            print(\r\n",
    "                'Majority class is %s and total number of classes is %s'\r\n",
    "                % (self.maj_class_, len(self.unique_classes_)))\r\n",
    "\r\n",
    "    def transform(self, X, y):\r\n",
    "        \"\"\"\r\n",
    "        Applies oversampling transformation to data as proposed by\r\n",
    "        the ADASYN algorithm. Returns oversampled X,y\r\n",
    "        \"\"\"\r\n",
    "        self.new_X, self.new_y = self.oversample()\r\n",
    "\r\n",
    "    def fit_transform(self, X, y):\r\n",
    "        \"\"\"\r\n",
    "        Fits the data and then returns the transformed version\r\n",
    "        \"\"\"\r\n",
    "        self.fit(X, y)\r\n",
    "        self.new_X, self.new_y = self.oversample()\r\n",
    "\r\n",
    "        self.new_X = np.concatenate((self.new_X, self.X), axis=0)\r\n",
    "        self.new_y = np.concatenate((self.new_y, self.y), axis=0)\r\n",
    "\r\n",
    "        return self.new_X, self.new_y\r\n",
    "\r\n",
    "    def generate_samples(self, x, knns, knnLabels, cl):\r\n",
    "\r\n",
    "        # List to store synthetically generated samples and their labels\r\n",
    "        new_data = []\r\n",
    "        new_labels = []\r\n",
    "        for ind, elem in enumerate(x):\r\n",
    "            # calculating k-neighbors that belong to minority (their indexes in x)\r\n",
    "            # Unfortunately knn returns the example itself as a neighbor. So it needs\r\n",
    "            # to be ignored thats why it is iterated [1:-1] and\r\n",
    "            # knnLabelsp[ind][+1].\r\n",
    "            min_knns = [ele for index,ele in enumerate(knns[ind][1:-1])\r\n",
    "                         if knnLabels[ind][index +1] == cl]\r\n",
    "\r\n",
    "            if not min_knns:\r\n",
    "                continue\r\n",
    "\r\n",
    "            # generate gi synthetic examples for every minority example\r\n",
    "            for i in range(0, int(self.gi[ind])):\r\n",
    "                # randi holds an integer to choose a random minority kNNs\r\n",
    "                # randi = self.random_state_.random_integers(\r\n",
    "                #     0, len(min_knns) - 1)\r\n",
    "                randi = randint(0, len(min_knns) - 1)\r\n",
    "                # l is a random number in [0,1)\r\n",
    "                l = self.random_state_.random_sample()\r\n",
    "                # X[min_knns[randi]] is the Xzi on equation [5]\r\n",
    "                si = self.X[elem] + \\\r\n",
    "                    (self.X[min_knns[randi]] - self.X[elem]) * l\r\n",
    "                    \r\n",
    "                new_data.append(si)\r\n",
    "                new_labels.append(self.y[elem])\r\n",
    "                self.num_new += 1\r\n",
    "\r\n",
    "        return(np.asarray(new_data), np.asarray(new_labels))\r\n",
    "\r\n",
    "    def oversample(self):\r\n",
    "        \"\"\"\r\n",
    "        Preliminary calculations before generation of\r\n",
    "        synthetic samples. Calculates and stores as instance\r\n",
    "        variables: img_degree(d),G,ri,gi as defined by equations\r\n",
    "        [1],[2],[3],[4] in the original paper\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        try:\r\n",
    "            # Checking if variable exists, i.e. if fit() was called\r\n",
    "            self.unique_classes_ = self.unique_classes_\r\n",
    "        except:\r\n",
    "            raise RuntimeError(\"You need to fit() before applying tranform(),\"\r\n",
    "                               \"or simply fit_transform()\")\r\n",
    "        int_X = np.zeros([1, self.X.shape[1]])\r\n",
    "        int_y = np.zeros([1])\r\n",
    "        # Iterating through all minority classes to determine\r\n",
    "        # if they should be oversampled and to what extent\r\n",
    "        for cl in self.unique_classes_:\r\n",
    "            # Calculate imbalance degree and compare to threshold\r\n",
    "            imb_degree = float(self.clstats[cl]) / \\\r\n",
    "                self.clstats[self.maj_class_]\r\n",
    "            if imb_degree > self.imb_threshold:\r\n",
    "                if self.verbose:\r\n",
    "                    print('Class %s is within imbalance threshold' % cl)\r\n",
    "            else:\r\n",
    "                # G is the number of synthetic examples to be synthetically\r\n",
    "                # produced for the current minority class\r\n",
    "                self.G = (self.clstats[self.maj_class_] - self.clstats[cl]) \\\r\n",
    "                            * self.ratio\r\n",
    "\r\n",
    "                # ADASYN is built upon eucliden distance so p=2 default\r\n",
    "                self.nearest_neighbors_ = NearestNeighbors(n_neighbors=self.k + 1)\r\n",
    "                self.nearest_neighbors_.fit(self.X)\r\n",
    "\r\n",
    "                # keeping indexes of minority examples\r\n",
    "                minx = [ind for ind, exam in enumerate(self.X) if self.y[ind] == cl]\r\n",
    "\r\n",
    "                # Computing kNearestNeighbors for every minority example\r\n",
    "                knn = self.nearest_neighbors_.kneighbors(\r\n",
    "                    self.X[minx], return_distance=False)\r\n",
    "\r\n",
    "                # Getting labels of k-neighbors of each example to determine how many of them\r\n",
    "                # are of different class than the one being oversampled\r\n",
    "                knnLabels = self.y[knn.ravel()].reshape(knn.shape)\r\n",
    "\r\n",
    "                tempdi = [Counter(i) for i in knnLabels]\r\n",
    "\r\n",
    "                # Calculating ri as defined in ADASYN paper:\r\n",
    "                # No. of k-neighbors belonging to different class than the minority divided by K\r\n",
    "                # which is ratio of friendly/non-friendly neighbors\r\n",
    "                self.ri = np.array(\r\n",
    "                    [(sum(i.values())- i[cl]) / float(self.k) for i in tempdi])\r\n",
    "\r\n",
    "                # Normalizing so that ri is a density distribution (i.e.\r\n",
    "                # sum(ri)=1)\r\n",
    "                if np.sum(self.ri):\r\n",
    "                    self.ri = self.ri / np.sum(self.ri)\r\n",
    "\r\n",
    "                # Calculating #synthetic_examples that need to be generated for\r\n",
    "                # each minority instance and rounding to nearest integer because\r\n",
    "                # it can't produce e.g 2.35 new examples.\r\n",
    "                self.gi = np.rint(self.ri * self.G)\r\n",
    "\r\n",
    "                # Generation of synthetic samples\r\n",
    "                inter_X, inter_y = self.generate_samples(\r\n",
    "                                     minx, knn, knnLabels, cl)\r\n",
    "                # in case no samples where generated at all concatenation\r\n",
    "                # won't be attempted\r\n",
    "                if len(inter_X):\r\n",
    "                    int_X = np.concatenate((int_X, inter_X), axis=0)\r\n",
    "                if len(inter_y):\r\n",
    "                    int_y = np.concatenate((int_y, inter_y), axis=0)\r\n",
    "        # New samples are concatenated in the beggining of the X,y arrays\r\n",
    "        # index_new contains the indiced of artificial examples\r\n",
    "        self.index_new = [i for i in range(0,self.num_new)]\r\n",
    "        return(int_X[1:-1], int_y[1:-1])\r\n",
    "\r\n",
    "\r\n",
    "# =============================\r\n",
    "df = pd.read_csv('Data\\\\process.csv')\r\n",
    "X = df[['品牌类型']+['a{}'.format(i) for i in range(1, 9)] + ['B{}'.format(i) for i in range(1, 18)]]\r\n",
    "X = X.values\r\n",
    "y = df['购买意愿']\r\n",
    "y= y.values\r\n",
    "adsn = ADASYN(k=7,imb_threshold=0.1, ratio=0.75)\r\n",
    "new_X, new_y = adsn.fit_transform(X, y)\r\n",
    "\r\n",
    "print(len(new_X))\r\n",
    "print(sum(new_y))\r\n",
    "new_data=pd.DataFrame(new_X)\r\n",
    "new_data = pd.concat([new_data, pd.Series(new_y)], axis=1)\r\n",
    "new_data.columns = list(['品牌类型']+['a{}'.format(i) for i in range(1, 9)] + ['B{}'.format(i) for i in range(1, 18)] + ['购买意愿'])\r\n",
    "for i in list(['品牌类型']+['B{}'.format(i) for i in range(1, 18)] + ['购买意愿']):\r\n",
    "    new_data[i] = list(round(j) for j in new_data[i])\r\n",
    "\r\n",
    "new_data.to_csv('Data\\\\BigData_0.csv', index=False)\r\n",
    "\r\n",
    "np.savez('Data.npz', new_X, new_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 卡方检验\r\n",
    "# 原文件：chi-square.py\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "def calCon(df, colName, type=0):\r\n",
    "    if type == 0:\r\n",
    "        alList = list(set(df[colName]))\r\n",
    "        conList = [[], []]\r\n",
    "        conList[0] = [len(df[(df[colName] == i) & (df['购买意愿'] == 0)]) for i in alList]\r\n",
    "        conList[1] = [len(df[(df[colName] == i) & (df['购买意愿'] == 1)]) for i in alList]\r\n",
    "\r\n",
    "        con = chi2_contingency(np.array(conList).T)\r\n",
    "        with open('Data\\\\chi2\\\\卡方3.txt', 'a', encoding='utf-8') as f:\r\n",
    "            f.write(colName)\r\n",
    "            f.write('卡方值：{}\\nP-Value：{}\\n'.format(con[0], con[1]))\r\n",
    "            buy = [len(df[(df[colName] == i) & (df['购买意愿'] == 1)]) / len(df[df[colName] == i]) for i in alList]\r\n",
    "            t = 0\r\n",
    "            for i in alList:\r\n",
    "                f.write(str(i))\r\n",
    "                f.write('：')\r\n",
    "                f.write('%.2f%%' % (buy[t] * 100))\r\n",
    "                f.write('，正例数：{}，总数：{}'.format(len(df[(df[colName] == i) & (df['购买意愿'] == 1)]), len(df[df[colName] == i])))\r\n",
    "                f.write('\\n')\r\n",
    "                t+=1\r\n",
    "            f.write('\\n=============\\n')\r\n",
    "    else:\r\n",
    "        conList = [list(df['positive']), list(df['negative'])]\r\n",
    "        con = chi2_contingency(np.array(conList).T)\r\n",
    "        with open('Data\\\\chi2\\\\卡方3.txt', 'a', encoding='utf-8') as f:\r\n",
    "            f.write(colName)\r\n",
    "            f.write('卡方值：{}\\nP-Value：{}\\n'.format(con[0], con[1]))\r\n",
    "            alLen = len(df['colName'])\r\n",
    "            colNameL = list(df['colName'])\r\n",
    "            pL = list(df['positive'])\r\n",
    "            nL = list(df['negative'])\r\n",
    "            for i in range(alLen):\r\n",
    "                f.write(colNameL[i] + '：')\r\n",
    "                per = 0\r\n",
    "                try:\r\n",
    "                    per = pL[i] / (pL[i] + nL[i])\r\n",
    "                except:\r\n",
    "                    pass\r\n",
    "                f.write('%.2f%%' % (per * 100))\r\n",
    "                f.write('，正例数：{}，总数：{}\\n'.format(pL[i], pL[i] + nL[i]))\r\n",
    "            f.write('\\n=============\\n')\r\n",
    "\r\n",
    "    return colName, con\r\n",
    "\r\n",
    "allDf = pd.read_csv('Data\\\\tempData\\\\3.csv')\r\n",
    "testL = ['B1', 'B3', 'B5', 'B6', 'B7', 'B9', 'B11', 'B12']\r\n",
    "allList = []\r\n",
    "for i in testL:\r\n",
    "    c = calCon(allDf, i, type=0)\r\n",
    "    allList.append((c[0], c[1][0], c[1][1], int(i[1: ])))\r\n",
    "\r\n",
    "def cutDf(df, colName, *cut):\r\n",
    "    cutL = cut[0]\r\n",
    "    data = {'colName': [], 'positive': [], 'negative': []}\r\n",
    "    data['colName'] = ['(, {}]'.format(cutL[0])]\r\n",
    "    data['positive'] = [len(df[(df[colName] <= cutL[0]) & (df['购买意愿'] == 1)])]\r\n",
    "    data['negative'] = [len(df[(df[colName] <= cutL[0]) & (df['购买意愿'] == 0)])]\r\n",
    "\r\n",
    "    for i in range(1, len(cutL)):\r\n",
    "        data['colName'].append('({}, {}]'.format(cutL[i - 1], cutL[i]))\r\n",
    "        data['positive'].append(len(df[(df[colName] > cutL[i - 1]) & (df[colName] <= cutL[i]) & (df['购买意愿'] == 1)]))\r\n",
    "        data['negative'].append(len(df[(df[colName] > cutL[i - 1]) & (df[colName] <= cutL[i]) & (df['购买意愿'] == 0)]))\r\n",
    "    data['colName'].append('({}, )'.format(cutL[len(cutL) - 1]))\r\n",
    "    data['positive'].append(len(df[(df[colName] > cutL[len(cutL) - 1]) & (df['购买意愿'] == 1)]))\r\n",
    "    data['negative'].append(len(df[(df[colName] > cutL[len(cutL) - 1]) & (df['购买意愿'] == 0)]))\r\n",
    "\r\n",
    "    newDf = pd.DataFrame(data)\r\n",
    "    # print(newDf)\r\n",
    "    return calCon(newDf, colName, type=1)\r\n",
    "\r\n",
    "B2 = cutDf(allDf, 'B2', tuple(6 * i for i in range(1, 8)))\r\n",
    "B4 = cutDf(allDf, 'B4', tuple(3 * i for i in range(1, 7)))\r\n",
    "# B5 = cutDf(allDf, 'B5', tuple(6 * i for i in range(1, 9)))\r\n",
    "B8 = cutDf(allDf, 'B8', tuple(5 * i for i in range(5, 10)))\r\n",
    "B10 = cutDf(allDf, 'B10', tuple(5 * i for i in range(1, 6)))\r\n",
    "B13 = cutDf(allDf, 'B13', tuple(10 * i for i in range(1, 7)))\r\n",
    "B14 = cutDf(allDf, 'B14', (10,20,30,40,50))\r\n",
    "B15 = cutDf(allDf, 'B15', tuple(10 * i for i in range(1, 6)))\r\n",
    "B16 = cutDf(allDf, 'B16', tuple(10 * i for i in range(1, 6)))\r\n",
    "B17 = cutDf(allDf, 'B17', tuple(10 * i for i in range(1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题三：分类模型建立\r\n",
    "1. 决策树模型"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 决策树模型\r\n",
    "# 原文件：DT_T3.py\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\r\n",
    "from sklearn import tree\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import graphviz\r\n",
    "\r\n",
    "useList = ['品牌类型', 'PCA'] + ['B16', 'B17', 'B15', 'B11', 'B13', 'B3', 'B2', 'B12', 'B14']\r\n",
    "\r\n",
    "# 这里使用主成分分析的系数矩阵\r\n",
    "def change2PCA(dfName):\r\n",
    "    nums = np.array([-0.35052756581444017, -0.3634850427685319, -0.33490475542161724,\r\n",
    "        -0.3584034911899144, -0.35780027944370135, -0.3553634343740415,\r\n",
    "        -0.3556601815862112, -0.3515628199349126])\r\n",
    "\r\n",
    "    PCAList = []\r\n",
    "    for index, row in dfName.iterrows():\r\n",
    "        m = row[['a{}'.format(i) for i in range(1, 9)]]\r\n",
    "        PCAList.append(np.dot(nums, m))\r\n",
    "    \r\n",
    "    dfName['PCA'] = PCAList\r\n",
    "    return dfName\r\n",
    "\r\n",
    "df = pd.read_csv('Data\\\\BigData_0.csv')\r\n",
    "df = change2PCA(df)\r\n",
    "\r\n",
    "X = df[useList].values\r\n",
    "y = df['购买意愿'].values\r\n",
    "\r\n",
    "shuffled_index = np.random.permutation(len(df))\r\n",
    "X = X[shuffled_index, :]\r\n",
    "y = y[shuffled_index]\r\n",
    "split_index = int(len(df) * 0.7)\r\n",
    "X_train = X[:split_index, :]\r\n",
    "y_train = y[:split_index]\r\n",
    "\r\n",
    "X_test = X[split_index:, :]\r\n",
    "y_test = y[split_index:]\r\n",
    "\r\n",
    "dt = tree.DecisionTreeClassifier()\r\n",
    "dt.fit(X_train, y_train)\r\n",
    "y_train_fit = dt.predict(X_train)\r\n",
    "y_pred = dt.predict(X_test)\r\n",
    "print('训练集acc:{}，rec:{},\\n\\t pre:{}, f1:{}'.format(accuracy_score(y_train, y_train_fit), recall_score(y_train, y_train_fit), precision_score(y_train, y_train_fit), f1_score(y_train, y_train_fit)))\r\n",
    "print('测试集acc:{}，rec:{},\\n\\t pre:{}, f1:{}'.format(accuracy_score(y_test, y_pred), recall_score(y_test, y_pred), precision_score(y_test, y_pred), f1_score(y_test, y_pred)))\r\n",
    "print(dt.get_depth())\r\n",
    "\r\n",
    "\r\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, class_names=True)\r\n",
    "graph = graphviz.Source(dot_data)\r\n",
    "graph.render('tree')\r\n",
    "\r\n",
    "testDf = pd.read_csv('Data\\\\testData_T3.csv')\r\n",
    "testDf['B8'] = [2021-i for i in list(testDf['B10'])]\r\n",
    "\r\n",
    "testDf = change2PCA(testDf)\r\n",
    "\r\n",
    "testX = testDf[useList].values\r\n",
    "\r\n",
    "testY = dt.predict(testX)\r\n",
    "testDf['是否会购买？'] = testY\r\n",
    "\r\n",
    "print(testY)\r\n",
    "testDf.to_csv('Data\\\\T3Ans.csv', index=False)\r\n",
    "\r\n",
    "# print('原始集acc:{}，rec:{},\\n\\t pre:{}, f1:{}'.format(accuracy_score(tempY, tmepY_test), recall_score(tempY, tmepY_test), precision_score(tempY, tmepY_test), f1_score(tempY, tmepY_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题四：潜在客户挖掘\r\n",
    "1. 基于决策树模型的挖掘机制"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 初步挖掘\r\n",
    "# 原文件：DT_T4_init.py\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\r\n",
    "from sklearn import tree\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# 读取数据与预先处理\r\n",
    "\r\n",
    "useList = ['品牌类型', 'PCA'] + ['B16', 'B17', 'B15', 'B11', 'B13', 'B3', 'B2', 'B12', 'B14']\r\n",
    "# 这里使用主成分分析的系数矩阵\r\n",
    "def change2PCA(dfName):\r\n",
    "    nums = np.array([-0.35052756581444017, -0.3634850427685319, -0.33490475542161724,\r\n",
    "        -0.3584034911899144, -0.35780027944370135, -0.3553634343740415,\r\n",
    "        -0.3556601815862112, -0.3515628199349126])\r\n",
    "    \r\n",
    "    PCAList = []\r\n",
    "    for index, row in dfName.iterrows():\r\n",
    "        m = row[['a{}'.format(i) for i in range(1, 9)]]\r\n",
    "        PCAList.append(np.dot(nums, m))\r\n",
    "    \r\n",
    "    dfName['PCA'] = PCAList\r\n",
    "    return dfName\r\n",
    "\r\n",
    "df = pd.read_csv('Data\\\\BigData_0.csv')\r\n",
    "df = change2PCA(df)\r\n",
    "\r\n",
    "X = df[useList].values\r\n",
    "y = df['购买意愿'].values\r\n",
    "\r\n",
    "for i in range(-5, 6):\r\n",
    "    testDf = pd.read_csv('Data\\\\testData_T4.csv')\r\n",
    "    testDf['B8'] = [2021-k for k in list(testDf['B10'])]\r\n",
    "    tmp = np.array([1 + i / 100.0] * 15)\r\n",
    "    for k in list(['a{}'.format(m) for m in range(1, 9)]):\r\n",
    "        testDf[k] = testDf[k].values * tmp\r\n",
    "    testDf = change2PCA(testDf)\r\n",
    "    testX = testDf[useList].values\r\n",
    "\r\n",
    "    tmpNp = np.zeros(15)\r\n",
    "    for j in range(1000):\r\n",
    "        shuffled_index = np.random.permutation(len(df))\r\n",
    "        X = X[shuffled_index, :]\r\n",
    "        y = y[shuffled_index]\r\n",
    "        split_index = int(len(df) * 0.7)\r\n",
    "        X_train = X[:split_index, :]\r\n",
    "        y_train = y[:split_index]\r\n",
    "        X_test = X[split_index:, :]\r\n",
    "        y_test = y[split_index:]\r\n",
    "\r\n",
    "        dt = tree.DecisionTreeClassifier()\r\n",
    "        dt.fit(X_train, y_train)\r\n",
    "        y_train_fit = dt.predict(X_train)\r\n",
    "        y_pred = dt.predict(X_test)\r\n",
    "        # print('训练集acc:{}，rec:{},\\n\\t pre:{}, f1:{}'.format(accuracy_score(y_train, y_train_fit), recall_score(y_train, y_train_fit), precision_score(y_train, y_train_fit), f1_score(y_train, y_train_fit)))\r\n",
    "        # print('测试集acc:{}，rec:{},\\n\\t pre:{}, f1:{}'.format(accuracy_score(y_test, y_pred), recall_score(y_test, y_pred), precision_score(y_test, y_pred), f1_score(y_test, y_pred)))\r\n",
    "\r\n",
    "        testY = dt.predict(testX)\r\n",
    "        tmpNp += testY\r\n",
    "    \r\n",
    "    print(i, tmpNp.tolist())\r\n",
    "\r\n",
    "testDf['是否会购买？'] = testY\r\n",
    "\r\n",
    "print(testY)\r\n",
    "testDf.to_csv('Data\\\\T4Ans.csv', index=False)\r\n",
    "\r\n",
    "print('原始集acc:{}，rec:{},\\n\\t pre:{}, f1:{}'.format(accuracy_score(tempY, tmepY_test), recall_score(tempY, tmepY_test), precision_score(tempY, tmepY_test), f1_score(tempY, tmepY_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\r\n",
    "from sklearn import tree\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# 读取数据与预先处理\r\n",
    "newL = []\r\n",
    "\r\n",
    "useList = ['品牌类型', 'PCA'] + ['B16', 'B17', 'B15', 'B11', 'B13', 'B3', 'B2', 'B12', 'B14']\r\n",
    "# useList = ['品牌类型', 'PCA'] + ['B{}'.format(i) for i in range(1, 18)]\r\n",
    "# 这里使用主成分分析的系数矩阵\r\n",
    "def change2PCA(dfName):\r\n",
    "    nums = np.array([-0.35052756581444017, -0.3634850427685319, -0.33490475542161724,\r\n",
    "        -0.3584034911899144, -0.35780027944370135, -0.3553634343740415,\r\n",
    "        -0.3556601815862112, -0.3515628199349126])\r\n",
    "    \r\n",
    "    PCAList = []\r\n",
    "    for index, row in dfName.iterrows():\r\n",
    "        m = row[['a{}'.format(i) for i in range(1, 9)]]\r\n",
    "        PCAList.append(np.dot(nums, m))\r\n",
    "    \r\n",
    "    dfName['PCA'] = PCAList\r\n",
    "    return dfName\r\n",
    "\r\n",
    "df = pd.read_csv('Data\\\\BigData_0.csv')\r\n",
    "df = change2PCA(df)\r\n",
    "\r\n",
    "# X = df[['品牌类型', 'B16', 'B17', 'B15', 'B11', 'B13', 'B3', 'B2', 'B12', 'B14']].values\r\n",
    "# X = df[list(['a{}'.format(i) for i in range(1, 9)])].values\r\n",
    "X = df[useList].values\r\n",
    "y = df['购买意愿'].values\r\n",
    "\r\n",
    "def cal_prob(data, num):\r\n",
    "    global X, y\r\n",
    "    n = 0\r\n",
    "    nums = np.array([-0.35052756581444017, -0.3634850427685319, -0.33490475542161724,\r\n",
    "        -0.3584034911899144, -0.35780027944370135, -0.3553634343740415,\r\n",
    "        -0.3556601815862112, -0.3515628199349126])\r\n",
    "    data[list(['a{}'.format(i) for i in range(1, 9)])] *= 1 + num/100.0\r\n",
    "    data['PCA'] = np.dot(data[list(['a{}'.format(i) for i in range(1, 9)])].values, nums)\r\n",
    "    data = data[useList]\r\n",
    "    data=np.array([data.tolist()])\r\n",
    "    \r\n",
    "    for j in range(1000):\r\n",
    "        shuffled_index = np.random.permutation(len(df))\r\n",
    "        X = X[shuffled_index, :]\r\n",
    "        y = y[shuffled_index]\r\n",
    "        split_index = int(len(df) * 0.7)\r\n",
    "        X_train = X[:split_index, :]\r\n",
    "        y_train = y[:split_index]\r\n",
    "\r\n",
    "        dt = tree.DecisionTreeClassifier()\r\n",
    "        dt.fit(X_train, y_train)\r\n",
    "        data.reshape(1, -1)\r\n",
    "        pred = dt.predict(data)\r\n",
    "        n += pred[0]\r\n",
    "    print('prob', n/1000.0)\r\n",
    "    return n/1000.0\r\n",
    "\r\n",
    "testDf = pd.read_csv('Data\\\\testData_T4.csv')\r\n",
    "testDf['B8'] = [2021-k for k in list(testDf['B10'])]\r\n",
    "\r\n",
    "# 开始搜寻\r\n",
    "\r\n",
    "def search(left, right, depth):\r\n",
    "    if depth < 8:\r\n",
    "        m = cal_prob(testDf.loc[14], (left+right)/2)\r\n",
    "        l = cal_prob(testDf.loc[14], left)\r\n",
    "        r = cal_prob(testDf.loc[14], right)\r\n",
    "\r\n",
    "        print(l,m,r)\r\n",
    "        print(left,(left+right)/2, right)\r\n",
    "        if(l<0.75 and m>=0.75 and r>=0.75):\r\n",
    "            return search(left, (left+right)/2, depth+1)\r\n",
    "        elif(l<0.75 and m<0.75 and r>=0.75):\r\n",
    "            return search((left+right)/2, right, depth+1)\r\n",
    "        \r\n",
    "        \r\n",
    "    else:\r\n",
    "        return right, cal_prob(testDf.loc[14], right)\r\n",
    "\r\n",
    "a = search(2,3,0)\r\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 其他绘图\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "# 支持中文\r\n",
    "plt.rcParams['font.sans-serif'] = ['SimSun']  # 用来正常显示中文标签\r\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\r\n",
    "sns.set_palette(\"husl\")\r\n",
    "plt.style.use('ggplot')\r\n",
    "\r\n",
    "df = pd.read_csv('Data\\\\BigData.csv')\r\n",
    "\r\n",
    "# 相关系数热力图\r\n",
    "heatmap_data = df[list(['a{}'.format(i) for i in range(1, 9)])].corr()\r\n",
    "sns.heatmap(heatmap_data, annot=True)\r\n",
    "plt.title('相关系数')\r\n",
    "plt.savefig('Fig\\\\heatmap.png', bbox_inches='tight')\r\n",
    "plt.close()\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python391jvsc74a57bd080c611f7ce50016264de9f622e9e737e29cb81363444e6d20205f972d312f2bf"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}